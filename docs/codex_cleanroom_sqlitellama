```yaml
version: 1
id: BP-2026-02-03-THRESH-ASKSQL-BIG
project: Threshold/cleanroom
branch: feature/threshold-ask-sqlite-ollama
mode: big
priority: P1

title: "Threshold Cleanroom: Local SQLite Mirror + Ollama NL→SQL + Single `ask` CLI"

goal: |
  Build a local, fast, disposable query surface for Cleanroom using SQLite, and a single CLI entrypoint `ask`
  that uses an existing local Ollama model (phi-3 or llama-3-small) to translate natural language into
  SQLite SELECT-only queries.
  
  This work MUST:
  - Read ONLY from artifacts/validated/ as the canonical data source.
  - NOT read from proposals/, invalidated/, processed/, or reports/ for ingestion.
  - NOT modify any existing pipeline files or workflows.
  - Be local-first, disposable, and easy to upgrade later to Postgres.
  
  Outcome:
  - User can run: `python interface/ask/ask.py "question here"`
  - Script will:
    1) Ensure SQLite DB exists (or rebuild on demand)
    2) Call Ollama to generate SQL
    3) Enforce SQL safety (SELECT-only)
    4) Execute against SQLite opened READ-ONLY
    5) Print results to stdout (table + optional JSON)

deliverables:
  - "Create new directory: interface/ (new top-level interface layer; no changes to existing directories)."
  - "Create SQLite database generator that derives table/column layout from existing JSON schemas in schemas/*.schema.json."
  - "Create ingestion script that loads ONLY artifacts/validated/**.json into SQLite tables."
  - "Create Ollama prompt contract file and Ollama config file."
  - "Create single CLI: interface/ask/ask.py implementing NL→SQL→SQLite execution with SELECT-only enforcement."
  - "Create README: interface/README.md with exact commands to build DB and run ask."
  - "Create minimal verification script or steps and expected outputs."
  - "Optional: Create interface/requirements.txt (pyyaml, tabulate) to ensure repeatable installs."

definition_of_done:
  - "A fresh clone of the repo can run the system locally with ONLY the steps in interface/README.md."
  - "SQLite is built from artifacts/validated/ only; ingestion does not touch proposals/, invalidated/, processed/, or reports/."
  - "ask CLI opens SQLite in read-only mode for query execution."
  - "ask CLI rejects any non-SELECT SQL and rejects SQL containing INSERT/UPDATE/DELETE/DROP/ALTER/ATTACH/PRAGMA."
  - "ask CLI prints the generated SQL and prints result rows in a stable format."
  - "System uses existing local Ollama model (phi-3 or llama-3-small) and does not download new models."
  - "No changes are required to GitHub Actions or GitLab CI/CD workflows."
  - "All new code lives under interface/ only."

constraints:
  - "ZERO ambiguity: every file path, filename, and command must be explicitly specified."
  - "No inference required by Codex: do not say 'create something like', do not use vague wording."
  - "No exploration: implement exactly the steps listed below."
  - "No new external systems: local SQLite + local Ollama only."
  - "No writes to SQLite except during ingestion/build; runtime queries must be read-only."
  - "No ingestion from processed/: processed/ is archival source batches and must not be treated as canonical facts."
  - "If a missing schema field prevents table creation, the build must exit with a clear error message and non-zero code."

notes:
  - |
    FILES AND DIRECTORIES TO CREATE (all new content must live under interface/):
    
    1) Create directories:
       - interface/
       - interface/db/
       - interface/ingest/
       - interface/ask/
       - interface/models/
    
    2) Create files:
       - interface/requirements.txt
       - interface/db/build_db.py
       - interface/db/schema.sql                (generated by build_db.py; also written to disk)
       - interface/ingest/load_artifacts.py     (optional wrapper; may call db/build_db.py)
       - interface/ask/schema_prompt.txt
       - interface/models/ollama.txt
       - interface/ask/ask.py
       - interface/README.md
    
    ----------------------------------------------------------------------------
    interface/requirements.txt (exact contents):
    ----------------------------------------------------------------------------
    pyyaml==6.0.2
    tabulate==0.9.0
    
    ----------------------------------------------------------------------------
    SQLite DATABASE RULES (must be implemented exactly):
    ----------------------------------------------------------------------------
    A) Canonical ingestion source:
       - Only read JSON files under: artifacts/validated/
       - Only these schema folders are ingested if present:
         * artifacts/validated/authority_reference/
         * artifacts/validated/evidence_item/
         * artifacts/validated/money_flow/
         * artifacts/validated/field_validation/
       - Ignore everything else (including _manifests/, reports/, processed/, proposals/, invalidated/).
    
    B) Table creation MUST be derived from existing schema files:
       - Read schema files:
         * schemas/authority_reference.schema.json
         * schemas/evidence_item.schema.json
         * schemas/money_flow.schema.json
         * schemas/field_validation.schema.json
       - For each schema file:
         1) Parse JSON
         2) Take top-level "properties" keys as columns
         3) Determine SQL column types from JSON Schema "type":
            - "string"  -> TEXT
            - "number"  -> REAL
            - "integer" -> INTEGER
            - "boolean" -> INTEGER
            - "array"   -> TEXT  (store JSON string)
            - "object"  -> TEXT  (store JSON string)
            - missing/unknown -> TEXT
         4) Determine primary key column by schema name (MUST be exactly):
            - authority_reference -> authority_id
            - evidence_item       -> evidence_id
            - money_flow          -> flow_id
            - field_validation    -> validation_id
         5) If the required primary key column does not exist in properties:
            - Exit with error message: "Missing primary key column <col> in schema <schema_file>"
            - Exit code must be non-zero.
    
    C) Row storage rules:
       - Insert one row per JSON file in artifacts/validated/<schema>/*.json
       - Each column value is populated as:
         - if key exists in JSON object:
           * if value is dict/list -> JSON-dump to string
           * else -> store directly
         - if key missing -> NULL
       - Always store an additional column named `_raw_json` (TEXT) containing the full JSON-dumped object.
         * `_raw_json` MUST exist in all four tables even if not in schema properties.
         * `_raw_json` is for audit/trace and future-proofing.
    
    D) Indexing rules:
       - Create primary key index automatically via PRIMARY KEY.
       - Create index on editor_status if that column exists in that table.
       - Create index on event_date if that column exists in money_flow.
       - Create index on issue_date if that column exists in evidence_item.
    
    E) SQLite file location:
       - interface/db/clearlane.db
    
    ----------------------------------------------------------------------------
    interface/db/build_db.py (must implement exactly):
    ----------------------------------------------------------------------------
    Inputs:
      - repo_root auto-detected by `git rev-parse --show-toplevel` (fallback: current working dir)
    Outputs:
      - interface/db/schema.sql written to disk
      - interface/db/clearlane.db created (or replaced if --rebuild is used)
    CLI:
      - python interface/db/build_db.py --rebuild
    Behavior:
      1) Resolve repo root
      2) Locate schemas/ and artifacts/validated/
      3) Generate schema.sql (DROP TABLE IF EXISTS ...; CREATE TABLE ...; CREATE INDEX ...)
      4) Create SQLite database using generated schema.sql
      5) Ingest data from artifacts/validated/ into tables
      6) Print summary counts per table:
         - "authority_reference: <n>"
         - "evidence_item: <n>"
         - "money_flow: <n>"
         - "field_validation: <n>"
    
    ----------------------------------------------------------------------------
    interface/ask/schema_prompt.txt (exact contract; must be used verbatim by ask.py):
    ----------------------------------------------------------------------------
    You are a SQL generator.
    You may ONLY output valid SQLite SQL.
    You may ONLY output a single SELECT statement.
    You must NOT output explanations.
    You must NOT output markdown.
    You must NOT invent tables or columns.
    You must NOT use PRAGMA, ATTACH, DETACH.
    You must NOT modify data.
    You must NOT use multiple statements.
    
    The SQLite database has tables and columns exactly as provided below.
    Use only these.
    
    If the question cannot be answered from available tables/columns,
    output a SELECT that returns zero rows, for example:
    SELECT NULL WHERE 1=0
    
    ----------------------------------------------------------------------------
    interface/models/ollama.txt (exact contents):
    ----------------------------------------------------------------------------
    model_preference_order:
      - phi3
      - llama3
    temperature: 0.0
    top_p: 0.9
    num_predict: 512
    
    ----------------------------------------------------------------------------
    interface/ask/ask.py (must implement exactly):
    ----------------------------------------------------------------------------
    Inputs:
      - argv[1...] joined into a single question string
    Precondition:
      - interface/db/clearlane.db must exist; if missing, ask.py must print:
        "DB missing. Run: python interface/db/build_db.py --rebuild"
        and exit code 2.
    Steps:
      1) Load interface/ask/schema_prompt.txt
      2) Open SQLite DB in READ-ONLY mode:
         - sqlite3.connect("file:interface/db/clearlane.db?mode=ro", uri=True)
      3) Build a schema context string by reading sqlite table metadata:
         - Query sqlite_master to list tables
         - For each table, PRAGMA table_info(table) to list columns
      4) Construct Ollama prompt:
         - schema_prompt.txt
         - then literal "TABLES_AND_COLUMNS:" section listing each table and its columns
         - then literal "QUESTION:" line followed by the user question
      5) Call Ollama via subprocess (must be literal and work with local ollama CLI):
         - Command format:
           ollama run <MODEL_NAME> "<PROMPT_TEXT>"
         - MODEL_NAME selection:
           a) If env OLLAMA_MODEL is set, use it exactly.
           b) Else default to "phi3" (literal string).
      6) Capture stdout as SQL string.
      7) Enforce SQL safety EXACTLY:
         - Trim whitespace
         - Must start with "SELECT" (case-insensitive)
         - Must not contain any of these tokens (case-insensitive substring check):
           "insert", "update", "delete", "drop", "alter", "attach", "detach", "pragma", "vacuum", "create"
         - Must not contain ";" anywhere (reject multi-statement)
         - If fails, print:
           "Rejected SQL by safety gate."
           then print the SQL
           exit code 3.
      8) Print the SQL to stdout prefixed by:
         "SQL:"
      9) Execute SQL against SQLite
     10) Print results:
         - If zero rows: print "ROWS: 0"
         - Else print "ROWS: <n>"
         - Print a table using tabulate with headers from cursor.description
     11) Exit code 0 on success.
    
    ----------------------------------------------------------------------------
    interface/README.md (must include exact commands):
    ----------------------------------------------------------------------------
    Required sections and exact commands:
    
    A) Create venv (optional but recommended):
       python -m venv .venv
       source .venv/bin/activate   (mac/linux)
       .venv\\Scripts\\activate    (windows powershell)
    
    B) Install deps:
       pip install -r interface/requirements.txt
    
    C) Build DB:
       python interface/db/build_db.py --rebuild
    
    D) Ask a question:
       python interface/ask/ask.py "list 5 money_flow rows"
    
    E) Expected example output (must be literal example):
       SQL:
       SELECT flow_id FROM money_flow LIMIT 5
       ROWS: 5
       <tabulated output>
    
    ----------------------------------------------------------------------------
    MANUAL VERIFICATION STEPS (Codex must include these and expected outputs):
    ----------------------------------------------------------------------------
    1) Verify DB file exists:
       - interface/db/clearlane.db exists on disk
    2) Verify tables exist:
       - authority_reference, evidence_item, money_flow, field_validation
    3) Verify read-only mode:
       - ask.py must use uri=True with mode=ro
    4) Verify safety gate:
       - Running: python interface/ask/ask.py "drop table money_flow"
         must reject SQL and exit code 3
    5) Verify ingestion source restriction:
       - build_db.py must reference only artifacts/validated/
       - build_db.py must not reference proposals/, invalidated/, processed/, reports/
    
    ----------------------------------------------------------------------------
    DO NOT CHANGE (explicit non-goals):
    ----------------------------------------------------------------------------
    - Do not edit any existing directories: schemas/, artifacts/, proposals/, invalidated/, processed/, reports/, .github/
    - Do not add GitHub Actions workflows.
    - Do not add GitLab CI/CD config.
    - Do not add embeddings or vector search.
    - Do not add any UI or dashboard.

    ----------------------------------------------------------------------------
    AMENDMENTS 2026-02-03 (additive corrections; do not reinterpret earlier items):
    ----------------------------------------------------------------------------
    1) Fix schema property location:
       - Read columns from $defs.<schema_name>.properties; fallback to top-level properties only if present.

    2) Define array handling:
       - If a JSON artifact root is an array (the schema allows oneOf arrays), exit with a clear error and non-zero code rather than ingesting.

    3) Clarify behavior when DB exists:
       - If interface/db/clearlane.db exists and --rebuild is NOT provided, exit with a clear message and non-zero code to avoid accidental overwrite.

    4) Deterministic schema/column order:
       - Preserve schema-declared order when generating schema.sql; if unavailable, sort columns to keep schema.sql reproducible across runs.

    5) Missing schema files:
       - If any required schema file is missing, exit with a clear error message and non-zero code.

    6) JSON file selection rules:
       - Only ingest *.json files directly under the four validated schema folders; ignore subdirectories and non-JSON files.

    7) Ollama failure handling:
       - If `ollama run` exits non-zero or returns empty output, print a clear error and exit non-zero.

    8) Output format stability:
       - Use a fixed tabulate format (e.g., tablefmt="github") for stable output across environments.

    9) Field validation primary key correction:
       - Use primary key `fv_id` for field_validation (schema defines fv_id, not validation_id).

    10) Recursive validated ingestion:
       - Ingest *.json files recursively under artifacts/validated/<schema>/ (still restricted to the four schema folders).
       - Continue ignoring non-JSON files and any other top-level sources (proposals/, invalidated/, processed/, reports/).

    11) Skip JSON fragments under YAML artifact directories:
       - If any parent directory name ends with .yaml or .yml, ignore JSON files under that subtree.

    12) Deterministic primary key collisions:
       - When multiple JSON files yield the same required primary key, keep the first ingested row (files processed in sorted path order) and ignore later duplicates.
       - The build should print a per-table collision count when collisions occur.
```
